{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPL Gameweek Analysis – Notebook\n",
    "\n",
    "End-to-end workflow to:\n",
    "\n",
    "### A:\n",
    "    - Load imports \n",
    "    - Declare constants\n",
    "\n",
    "### B:\n",
    "    - Load FPL data from csv files\n",
    "    - Sanity check\n",
    "\n",
    "### C:\n",
    "    - Add Position\n",
    "    - Drop timestamps\n",
    "    - Attache team data to players\n",
    "\n",
    "- Build a per-player, per-gameweek feature table\n",
    "- Train a Random Forest regression model to predict points\n",
    "- Evaluate the model with a time-based validation\n",
    "- Build a snapshot for a target gameweek and generate predictions\n",
    "- Add consistency metrics & tiers\n",
    "- Select a best XI via ILP (strategy tuned via prior experimentation)\n",
    "- Suggest transfers and pick a starting XI from a given squad\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "- `players.csv`, `teams.csv`, `player_history.csv`, `fixtures.csv` are in the working directory.\n",
    "- Column names broadly match the standard FPL export (some robustness is built in).\n",
    "- You'll set `TARGET_GW` near the top of the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Imports & Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import pulp\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "TARGET_GW =19 # <-- Gameweek we are working to predict, change this as needed\n",
    "N_VAL_GWS = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Data Loading\n",
    "\n",
    "Load the four core CSVs and do basic sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_path = \"data/players.csv\"\n",
    "teams_path = \"data/teams.csv\"\n",
    "history_path = \"data/player_history.csv\"\n",
    "fixtures_path = \"data/fixtures.csv\"\n",
    "\n",
    "players = pd.read_csv(players_path)\n",
    "teams = pd.read_csv(teams_path)\n",
    "history = pd.read_csv(history_path)\n",
    "fixtures = pd.read_csv(fixtures_path)\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"players:\", players.shape)\n",
    "print(\"teams:\", teams.shape)\n",
    "print(\"history:\", history.shape)\n",
    "print(\"fixtures:\", fixtures.shape)\n",
    "\n",
    "print(\"\\nColumns:\")\n",
    "print(\"players: \", players.columns.tolist())\n",
    "print(\"teams: \", teams.columns.tolist())\n",
    "print(\"fixtures: \", fixtures.columns.tolist())\n",
    "print(\"history: \", history.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Normalise Players & Teams\n",
    "\n",
    "We derive a `position_label` and attach team metadata to players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_position_label(players_df):\n",
    "    df = players_df.copy()\n",
    "    pos_col = None\n",
    "    for cand in [\"position\", \"element_type\", \"pos\"]:\n",
    "        if cand in df.columns:\n",
    "            pos_col = cand\n",
    "            break\n",
    "    if pos_col is None:\n",
    "        raise ValueError(\"No position column found in players.csv (expected one of: position, element_type, pos).\")\n",
    "    if np.issubdtype(df[pos_col].dtype, np.number):\n",
    "        mapping = {1: \"GK\", 2: \"DEF\", 3: \"MID\", 4: \"FWD\"}\n",
    "        df[\"position_label\"] = df[pos_col].map(mapping)\n",
    "    else:\n",
    "        mapping = {\n",
    "            \"GKP\": \"GK\", \"GK\": \"GK\",\n",
    "            \"DEF\": \"DEF\", \"D\": \"DEF\",\n",
    "            \"MID\": \"MID\", \"M\": \"MID\",\n",
    "            \"FWD\": \"FWD\", \"F\": \"FWD\",\n",
    "        }\n",
    "        df[\"position_label\"] = df[pos_col].map(mapping).fillna(df[pos_col])\n",
    "    return df\n",
    "\n",
    "players = derive_position_label(players)\n",
    "\n",
    "teams_ren = teams.rename(columns={\n",
    "    \"id\": \"team_row_id\",\n",
    "    \"fpl_team_id\": \"team_fpl_id\"\n",
    "})\n",
    "\n",
    "team_key_candidates = [\"team_id\", \"team\", \"team_fpl_id\"]\n",
    "team_key = None\n",
    "for cand in team_key_candidates:\n",
    "    if cand in players.columns:\n",
    "        team_key = cand\n",
    "        break\n",
    "if team_key is None:\n",
    "    raise ValueError(\"Could not find team reference column in players (expected team_id/team/team_fpl_id).\")\n",
    "\n",
    "if \"team_fpl_id\" in teams_ren.columns and players[team_key].isin(teams_ren[\"team_fpl_id\"]).all():\n",
    "    players_meta = players.merge(\n",
    "        teams_ren,\n",
    "        left_on=team_key,\n",
    "        right_on=\"team_fpl_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "else:\n",
    "    players_meta = players.merge(\n",
    "        teams_ren,\n",
    "        left_on=team_key,\n",
    "        right_on=\"team_row_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "players_meta.rename(columns={\n",
    "    \"name\": \"team_name\",\n",
    "    \"short_name\": \"team_short_name\",\n",
    "    \"strength\": \"team_strength\"\n",
    "}, inplace=True)\n",
    "\n",
    "players_meta.drop(columns={\n",
    "    \"updated_at\",\n",
    "    \"created_at\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"players_meta columns:\")\n",
    "print(players_meta.columns.tolist())\n",
    "display(players_meta.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Build Master Per-Player Per-GW Table\n",
    "\n",
    "Join history to players & fixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incase columns are named differently. \n",
    "\n",
    "player_id_key_candidates = [\"fpl_player_id\", \"element\", \"id\"]\n",
    "player_id_key = None\n",
    "for cand in player_id_key_candidates:\n",
    "    if cand in players_meta.columns:\n",
    "        player_id_key = cand\n",
    "        break\n",
    "if player_id_key is None:\n",
    "    raise ValueError(\"Could not find FPL player id column in players_meta (expected fpl_player_id/element/id).\")\n",
    "\n",
    "master = history.merge(\n",
    "    players_meta,\n",
    "    left_on=\"player_id\",\n",
    "    right_on=player_id_key,\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_player\")\n",
    ")\n",
    "\n",
    "fix = fixtures.copy()\n",
    "\n",
    "fix_long_home = fix.copy()\n",
    "fix_long_home[\"team_fpl_id\"] = fix_long_home[\"team_h\"]\n",
    "fix_long_home[\"opponent_fpl_id\"] = fix_long_home[\"team_a\"]\n",
    "fix_long_home[\"is_home\"] = True\n",
    "fix_long_home[\"fixture_difficulty\"] = fix_long_home[\"difficulty_h\"]\n",
    "fix_long_home[\"goals_for\"] = fix_long_home[\"team_h_score\"]\n",
    "fix_long_home[\"goals_against\"] = fix_long_home[\"team_a_score\"]\n",
    "\n",
    "fix_long_away = fix.copy()\n",
    "fix_long_away[\"team_fpl_id\"] = fix_long_away[\"team_a\"]\n",
    "fix_long_away[\"opponent_fpl_id\"] = fix_long_away[\"team_h\"]\n",
    "fix_long_away[\"is_home\"] = False\n",
    "fix_long_away[\"fixture_difficulty\"] = fix_long_away[\"difficulty_a\"]\n",
    "fix_long_away[\"goals_for\"] = fix_long_away[\"team_a_score\"]\n",
    "fix_long_away[\"goals_against\"] = fix_long_away[\"team_h_score\"]\n",
    "\n",
    "fix_long = pd.concat([fix_long_home, fix_long_away], ignore_index=True)\n",
    "for col in [\"goals_for\", \"goals_against\"]:\n",
    "    fix_long[col] = fix_long[col].fillna(0.0)\n",
    "\n",
    "if \"gameweek\" not in master.columns:\n",
    "    raise ValueError(\"Expected 'gameweek' column in player_history.\")\n",
    "\n",
    "master = master.merge(\n",
    "    fix_long[[\"event\", \"team_fpl_id\", \"opponent_fpl_id\", \"is_home\", \"fixture_difficulty\", \"goals_for\", \"goals_against\"]],\n",
    "    left_on=[\"gameweek\", \"team_fpl_id\"],\n",
    "    right_on=[\"event\", \"team_fpl_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "master.drop(columns=[\"event\"], inplace=True)\n",
    "master[\"is_home_int\"] = master[\"is_home\"].astype(float)\n",
    "\n",
    "print(\"master shape:\", master.shape)\n",
    "display(master.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Team-Level Rolling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(fix_long[fix_long[\"team_fpl_id\"]==1])\n",
    "team_gw = (\n",
    "    fix_long\n",
    "    .groupby([\"team_fpl_id\", \"event\"], as_index=False)\n",
    "    .agg(\n",
    "        goals_for=(\"goals_for\", \"sum\"),\n",
    "        goals_against=(\"goals_against\", \"sum\"),\n",
    "    )\n",
    "    .rename(columns={\"event\": \"gameweek\"})\n",
    ")\n",
    "\n",
    "team_gw = team_gw.sort_values([\"team_fpl_id\", \"gameweek\"])\n",
    "team_gw[\"goals_for_3gw\"] = (\n",
    "    team_gw\n",
    "    .groupby(\"team_fpl_id\")[\"goals_for\"]\n",
    "    .rolling(3, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "team_gw[\"goals_against_3gw\"] = (\n",
    "    team_gw\n",
    "    .groupby(\"team_fpl_id\")[\"goals_against\"]\n",
    "    .rolling(3, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "master = master.merge(\n",
    "    team_gw[[\"team_fpl_id\", \"gameweek\", \"goals_for_3gw\", \"goals_against_3gw\"]],\n",
    "    on=[\"team_fpl_id\", \"gameweek\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "opp_gw = team_gw.rename(columns={\n",
    "    \"team_fpl_id\": \"opponent_fpl_id\",\n",
    "    \"goals_for_3gw\": \"opp_goals_for_3gw\",\n",
    "    \"goals_against_3gw\": \"opp_goals_against_3gw\"\n",
    "})\n",
    "\n",
    "master = master.merge(\n",
    "    opp_gw[[\"opponent_fpl_id\", \"gameweek\", \"opp_goals_for_3gw\", \"opp_goals_against_3gw\"]],\n",
    "    on=[\"opponent_fpl_id\", \"gameweek\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"master with team features shape:\", master.shape)\n",
    "display(master.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Player-Level Rolling Features & Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.sort_values([\"player_id\", \"gameweek\"])\n",
    "\n",
    "def add_player_rolling_features(df):\n",
    "    df = df.copy()\n",
    "    grp = df.groupby(\"player_id\")\n",
    "    df[\"roll_points_3wk\"] = grp[\"total_points\"].rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df[\"roll_points_5wk\"] = grp[\"total_points\"].rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df[\"form_custom\"] = 0.62 * df[\"roll_points_3wk\"] + 0.38 * df[\"roll_points_5wk\"]\n",
    "    df[\"roll_minutes_3wk\"] = grp[\"minutes\"].rolling(3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df[\"lag1_points\"] = grp[\"total_points\"].shift(1)\n",
    "    df[\"lag1_minutes\"] = grp[\"minutes\"].shift(1)\n",
    "    if \"ict_index\" in df.columns:\n",
    "        df[\"ict_index_season\"] = grp[\"ict_index\"].expanding().mean().reset_index(level=0, drop=True)\n",
    "    else:\n",
    "        df[\"ict_index_season\"] = np.nan\n",
    "    return df\n",
    "\n",
    "master = add_player_rolling_features(master)\n",
    "\n",
    "if \"now_cost\" in master.columns:\n",
    "    master[\"now_cost_m\"] = master[\"now_cost\"] / 10.0\n",
    "else:\n",
    "    master[\"now_cost_m\"] = np.nan\n",
    "\n",
    "if \"team_strength\" in master.columns:\n",
    "    opp_strength = teams_ren.rename(columns={\n",
    "        \"team_fpl_id\": \"opponent_fpl_id\",\n",
    "        \"team_strength\": \"opp_team_strength\"\n",
    "    })[[\"opponent_fpl_id\", \"opp_team_strength\"]] if \"team_strength\" in teams_ren.columns else None\n",
    "    if opp_strength is not None:\n",
    "        master = master.merge(opp_strength, on=\"opponent_fpl_id\", how=\"left\")\n",
    "        master[\"team_vs_opp_strength\"] = master[\"team_strength\"] - master[\"opp_team_strength\"]\n",
    "    else:\n",
    "        master[\"team_vs_opp_strength\"] = np.nan\n",
    "else:\n",
    "    master[\"team_vs_opp_strength\"] = np.nan\n",
    "\n",
    "print(\"master with rolling features shape:\", master.shape)\n",
    "display(master.head(20))\n",
    "\n",
    "\n",
    "master.to_csv(\"data/master_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Modeling Dataset & Time-Based Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"total_points\"\n",
    "\n",
    "numeric_features = [\n",
    "    \"form_custom\",\n",
    "    \"roll_points_3wk\",\n",
    "    \"roll_points_5wk\",\n",
    "    \"roll_minutes_3wk\",\n",
    "    \"lag1_points\",\n",
    "    \"lag1_minutes\",\n",
    "    \"minutes\",\n",
    "    \"fixture_difficulty\",\n",
    "    \"goals_for_3gw\",\n",
    "    \"goals_against_3gw\",\n",
    "    \"opp_goals_for_3gw\",\n",
    "    \"opp_goals_against_3gw\",\n",
    "    \"ict_index_season\",\n",
    "    \"now_cost_m\",\n",
    "    \"team_vs_opp_strength\",\n",
    "    \"is_home_int\",\n",
    "]\n",
    "\n",
    "model_df = master[master[\"roll_points_5wk\"] > 0].copy()\n",
    "#model_df = master.copy()\n",
    "model_df = model_df.sort_values([\"player_id\", \"gameweek\"])\n",
    "model_df = model_df.dropna(subset=[target_col])\n",
    "\n",
    "cat_features = [\"position_label\"]\n",
    "\n",
    "core_cols = [\"player_id\", \"player_name\", \"team_short_name\", \"gameweek\", target_col]\n",
    "core_cols = [c for c in core_cols if c in model_df.columns]\n",
    "cols_needed = core_cols + [c for c in numeric_features if c in model_df.columns] + cat_features\n",
    "cols_needed = list(dict.fromkeys(cols_needed))\n",
    "model_df = model_df[cols_needed].copy()\n",
    "\n",
    "print(\"model_df shape:\", model_df.shape)\n",
    "display(model_df.head())\n",
    "\n",
    "all_gws = sorted(model_df[\"gameweek\"].unique())\n",
    "if len(all_gws) <= N_VAL_GWS:\n",
    "    val_gws = all_gws[int(len(all_gws) / 2):]\n",
    "else:\n",
    "    val_gws = all_gws[-N_VAL_GWS:]\n",
    "train_gws = [gw for gw in all_gws if gw not in val_gws]\n",
    "\n",
    "print(\"Train GWs:\", train_gws)\n",
    "print(\"Val GWs:\", val_gws)\n",
    "\n",
    "train_mask = model_df[\"gameweek\"].isin(train_gws)\n",
    "val_mask = model_df[\"gameweek\"].isin(val_gws)\n",
    "\n",
    "X_num_train = model_df.loc[train_mask, numeric_features].fillna(0.0)\n",
    "X_cat_train = pd.get_dummies(model_df.loc[train_mask, cat_features], drop_first=False)\n",
    "X_train = pd.concat([X_num_train, X_cat_train], axis=1)\n",
    "y_train = model_df.loc[train_mask, target_col].values\n",
    "\n",
    "X_num_val = model_df.loc[val_mask, numeric_features].fillna(0.0)\n",
    "X_cat_val = pd.get_dummies(model_df.loc[val_mask, cat_features], drop_first=False)\n",
    "X_cat_val = X_cat_val.reindex(columns=X_cat_train.columns, fill_value=0)\n",
    "X_val = pd.concat([X_num_val, X_cat_val], axis=1)\n",
    "y_val = model_df.loc[val_mask, target_col].values\n",
    "\n",
    "print(\"Train X shape:\", X_train.shape, \"Val X shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. Baseline & Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val_pred = model_df.loc[val_mask, \"form_custom\"].fillna(0.0).values\n",
    "\n",
    "rf_full = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf_full.fit(X_train, y_train)\n",
    "y_val_pred_rf = rf_full.predict(X_val)\n",
    "\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name:20s} MAE={mae:6.3f} | R²={r2:6.3f}\")\n",
    "\n",
    "print(\"Validation performance (target = total_points):\")\n",
    "print_metrics(\"Baseline (form)\", y_val, baseline_val_pred)\n",
    "print_metrics(\"RF full\",         y_val, y_val_pred_rf)\n",
    "\n",
    "fi = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"importance\": rf_full.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop RF feature importances:\")\n",
    "display(fi.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Consistency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_cols = [\"player_id\", \"web_name\", \"team_short_name\", \"position_label\", \"total_points\", \"minutes\"]\n",
    "missing = [c for c in cons_cols if c not in master.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in master for consistency calc: {missing}\")\n",
    "\n",
    "cons_df = master[cons_cols].copy()\n",
    "\n",
    "player_cons_all = (\n",
    "    cons_df.groupby([\"player_id\", \"web_name\", \"team_short_name\", \"position_label\"])\n",
    "    .agg(\n",
    "        points_mean=(\"total_points\", \"mean\"),\n",
    "        points_std=(\"total_points\", \"std\"),\n",
    "        minutes_mean=(\"minutes\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "player_cons_all[\"points_std\"] = player_cons_all[\"points_std\"].fillna(0.0)\n",
    "player_cons_all[\"consistency_score\"] = player_cons_all[\"points_mean\"] / (1.0 + player_cons_all[\"points_std\"])\n",
    "\n",
    "print(\"Player-level consistency sample:\")\n",
    "display(player_cons_all.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J. Snapshot for Target GW & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_mask = model_df[\"gameweek\"] == TARGET_GW\n",
    "\n",
    "X_num_snap = model_df.loc[snap_mask, numeric_features].fillna(0.0)\n",
    "X_cat_snap = pd.get_dummies(model_df.loc[snap_mask, cat_features], drop_first=False)\n",
    "X_cat_snap = X_cat_snap.reindex(columns=X_train.columns[len(numeric_features):], fill_value=0)\n",
    "X_snap = pd.concat([X_num_snap, X_cat_snap], axis=1)\n",
    "\n",
    "snap_core_cols = [\"player_id\", \"player_name\", \"team_short_name\", \"position_label\", \"gameweek\"]\n",
    "snap_core_cols = [c for c in snap_core_cols if c in model_df.columns]\n",
    "snap_core = model_df.loc[snap_mask, snap_core_cols].copy()\n",
    "\n",
    "snap_core[\"pred_rf_full\"] = rf_full.predict(X_snap)\n",
    "snap_core[\"form_custom\"] = model_df.loc[snap_mask, \"form_custom\"].values\n",
    "\n",
    "merge_cols = [\"player_id\", \"gameweek\"]\n",
    "extra_cols = [\"minutes\", \"now_cost_m\", \"fixture_difficulty\", \"is_home_int\", \"team_fpl_id\", \"opponent_fpl_id\", \"roll_minutes_3wk\"]\n",
    "extra_cols = [c for c in extra_cols if c in master.columns]\n",
    "\n",
    "snapshot_df = snap_core.merge(\n",
    "    master[merge_cols + extra_cols].drop_duplicates(merge_cols),\n",
    "    on=[\"player_id\", \"gameweek\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "snapshot_df = snapshot_df.merge(\n",
    "    player_cons_all[[\"player_id\", \"points_mean\", \"consistency_score\"]],\n",
    "    on=\"player_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Snapshot for TARGET_GW={TARGET_GW}:\")\n",
    "display(snapshot_df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K. Position Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_position_tiers(df, score_col=\"pred_rf_full\"):\n",
    "    df = df.copy()\n",
    "    if score_col not in df.columns:\n",
    "        raise ValueError(f\"{score_col} not in df.\")\n",
    "    def tier_for_group(g):\n",
    "        pct = g[score_col].rank(pct=True)\n",
    "        tiers = np.select(\n",
    "            [\n",
    "                pct >= 0.85,\n",
    "                pct >= 0.70,\n",
    "                pct >= 0.50,\n",
    "            ],\n",
    "            [\"S\", \"A\", \"B\"],\n",
    "            default=\"C\",\n",
    "        )\n",
    "        return pd.Series(tiers, index=g.index)\n",
    "    df[\"tier\"] = df.groupby(\"position_label\", group_keys=False).apply(tier_for_group)\n",
    "    return df\n",
    "\n",
    "test = snapshot_df.merge(players_meta, left_on=\"player_id\", right_on=\"fpl_player_id\", how=\"inner\")\n",
    "snapshot_df[\"player_name\"] = test[\"web_name\"]\n",
    "#print(test.columns)\n",
    "snapshot_df = add_position_tiers(snapshot_df, score_col=\"pred_rf_full\")\n",
    "display(snapshot_df[[\n",
    "    \"player_id\", \"player_name\", \"team_short_name\", \"position_label\",\n",
    "    \"pred_rf_full\", \"form_custom\", \"points_mean\", \"consistency_score\", \"tier\"\n",
    "]].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L. Tuned Strategy Hyperparameters & Selection Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONS_MIN_POINTS   = 2.5\n",
    "CONS_MIN_SCORE    = 0.3\n",
    "CONS_BOOST_WEIGHT = 0.09\n",
    "\n",
    "COST_WEIGHT   = 0.03\n",
    "BLEND_W_FULL  = 0.7\n",
    "BLEND_W_STRICT = 0.3\n",
    "\n",
    "POS_WEIGHTS = {\n",
    "    \"GK\": 1.00,\n",
    "    \"DEF\": 0.95,\n",
    "    \"MID\": 1.05,\n",
    "    \"FWD\": 1.08,\n",
    "}\n",
    "\n",
    "def apply_consistency_filter(df,\n",
    "                             min_points_mean=CONS_MIN_POINTS,\n",
    "                             min_consistency=CONS_MIN_SCORE):\n",
    "    df = df.copy()\n",
    "    if \"points_mean\" not in df.columns or \"consistency_score\" not in df.columns:\n",
    "        return df\n",
    "    mask = (\n",
    "        (df[\"points_mean\"] >= min_points_mean) &\n",
    "        (df[\"consistency_score\"] >= min_consistency)\n",
    "    )\n",
    "    return df[mask].copy()\n",
    "\n",
    "def build_selection_score(df):\n",
    "    df = df.copy()\n",
    "    if \"pred_rf_full\" not in df.columns:\n",
    "        raise ValueError(\"pred_rf_full not in df; run prediction pipeline first.\")\n",
    "    base = df[\"pred_rf_full\"].astype(float)\n",
    "    if \"form_custom\" in df.columns:\n",
    "        base += 0.05 * df[\"form_custom\"].fillna(0.0)\n",
    "    if \"def_form_custom\" in df.columns:\n",
    "        base += np.where(\n",
    "            df[\"position_label\"] == \"DEF\",\n",
    "            0.10 * df[\"def_form_custom\"].fillna(0.0),\n",
    "            0.0,\n",
    "        )\n",
    "    elif \"def_attacking_index\" in df.columns:\n",
    "        base += np.where(\n",
    "            df[\"position_label\"] == \"DEF\",\n",
    "            0.05 * df[\"def_attacking_index\"].fillna(0.0),\n",
    "            0.0,\n",
    "        )\n",
    "    if \"now_cost_m\" in df.columns:\n",
    "        base += COST_WEIGHT * df[\"now_cost_m\"].fillna(0.0)\n",
    "    if \"position_label\" in df.columns and \"POS_WEIGHTS\" in globals():\n",
    "        pos_w = df[\"position_label\"].map(POS_WEIGHTS).fillna(1.0)\n",
    "        base = base * pos_w\n",
    "    if \"consistency_score\" in df.columns:\n",
    "        cons = df[\"consistency_score\"].fillna(0.0)\n",
    "        cons_clipped = np.clip(cons, 0, 3)\n",
    "        base += CONS_BOOST_WEIGHT * cons_clipped\n",
    "    return base\n",
    "\n",
    "snapshot_df[\"score_for_xi\"] = build_selection_score(snapshot_df)\n",
    "display(snapshot_df[[\n",
    "    \"player_id\", \"player_name\", \"team_short_name\", \"position_label\",\n",
    "    \"pred_rf_full\", \"form_custom\", \"now_cost_m\",\n",
    "    \"points_mean\", \"consistency_score\", \"tier\", \"score_for_xi\"\n",
    "]].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M. Best XI Selector (ILP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_xi_ilp(\n",
    "    df,\n",
    "    budget_m=100.0,\n",
    "    max_from_team=3,\n",
    "    use_active_filter=True,\n",
    "    use_consistency_filter=True,\n",
    "    score_col=\"score_for_xi\",\n",
    "):\n",
    "    df = df.copy()\n",
    "    if use_active_filter and \"roll_minutes_3wk\" in df.columns:\n",
    "        df = df[df[\"roll_minutes_3wk\"] > 0].copy()\n",
    "    if use_consistency_filter:\n",
    "        df = apply_consistency_filter(df)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No players left after filters in select_best_xi_ilp.\")\n",
    "    if score_col not in df.columns:\n",
    "        df[score_col] = build_selection_score(df)\n",
    "    if \"now_cost_m\" not in df.columns:\n",
    "        raise ValueError(\"now_cost_m not in df; needed for budget constraint.\")\n",
    "    df = df[df[score_col].notna()].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No players with valid scores in select_best_xi_ilp.\")\n",
    "    prob = pulp.LpProblem(\"Best_XI\", pulp.LpMaximize)\n",
    "    indices = list(df.index)\n",
    "    x = {i: pulp.LpVariable(f\"x_{i}\", cat=\"Binary\") for i in indices}\n",
    "    prob += pulp.lpSum(df.loc[i, score_col] * x[i] for i in indices)\n",
    "    prob += pulp.lpSum(x[i] for i in indices) == 11\n",
    "    pos_bounds = {\n",
    "        \"GK\": (1, 1),\n",
    "        \"DEF\": (3, 5),\n",
    "        \"MID\": (2, 5),\n",
    "        \"FWD\": (1, 3),\n",
    "    }\n",
    "    for pos, (min_c, max_c) in pos_bounds.items():\n",
    "        idx_pos = df.index[df[\"position_label\"] == pos].tolist()\n",
    "        if idx_pos:\n",
    "            prob += pulp.lpSum(x[i] for i in idx_pos) >= min_c\n",
    "            prob += pulp.lpSum(x[i] for i in idx_pos) <= max_c\n",
    "    prob += pulp.lpSum(df.loc[i, \"now_cost_m\"] * x[i] for i in indices) <= budget_m\n",
    "    for team, grp in df.groupby(\"team_short_name\"):\n",
    "        idx_team = grp.index.tolist()\n",
    "        prob += pulp.lpSum(x[i] for i in idx_team) <= max_from_team\n",
    "    _ = prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    selected_idx = [i for i in indices if pulp.value(x[i]) == 1]\n",
    "    xi = df.loc[selected_idx].copy()\n",
    "    xi = xi.sort_values([\"position_label\", score_col], ascending=[True, False])\n",
    "    xi[\"selection_score\"] = xi[score_col]\n",
    "    total_cost = xi[\"now_cost_m\"].sum()\n",
    "    total_score = xi[score_col].sum()\n",
    "    print(f\"Best XI total selection score: {total_score:.2f}\")\n",
    "    print(f\"Total cost: {total_cost:.1f}m (budget {budget_m:.1f}m)\")\n",
    "    return xi\n",
    "\n",
    "best_xi = select_best_xi_ilp(snapshot_df, budget_m=100.0, max_from_team=3)\n",
    "display(best_xi[[\n",
    "    \"player_id\", \"player_name\", \"team_short_name\", \"position_label\",\n",
    "    \"now_cost_m\", \"pred_rf_full\", \"selection_score\", \"tier\",\n",
    "    \"points_mean\", \"consistency_score\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N. Transfer Suggestor (Greedy, by player_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_transfers_greedy(\n",
    "    snapshot_df,\n",
    "    current_squad_ids,\n",
    "    n_transfers=1,\n",
    "    budget_m=100.0,\n",
    "    max_from_team=3,\n",
    "    use_active_filter=True,\n",
    "    use_consistency_filter=True,\n",
    "    score_col=\"score_for_xi\",\n",
    "):\n",
    "    df = snapshot_df.copy()\n",
    "    if use_active_filter and \"roll_minutes_3wk\" in df.columns:\n",
    "        df = df[df[\"roll_minutes_3wk\"] > 0].copy()\n",
    "    if use_consistency_filter:\n",
    "        df = apply_consistency_filter(df)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No players left after filters in suggest_transfers_greedy.\")\n",
    "    if score_col not in df.columns:\n",
    "        df[score_col] = build_selection_score(df)\n",
    "    if \"now_cost_m\" not in df.columns:\n",
    "        raise ValueError(\"now_cost_m missing; needed for transfer suggestions.\")\n",
    "    df = df[df[score_col].notna()].copy()\n",
    "    squad_mask = df[\"player_id\"].isin(current_squad_ids)\n",
    "    squad = df[squad_mask].copy()\n",
    "    pool = df[~squad_mask].copy()\n",
    "    if squad.empty:\n",
    "        raise ValueError(\"No overlapping players between snapshot_df and current_squad_ids.\")\n",
    "    current_cost = squad[\"now_cost_m\"].sum()\n",
    "    team_counts = squad[\"team_short_name\"].value_counts().to_dict()\n",
    "    suggestions = []\n",
    "    for _, row_out in squad.iterrows():\n",
    "        pid_out = row_out[\"player_id\"]\n",
    "        cost_out = row_out[\"now_cost_m\"]\n",
    "        score_out = row_out[score_col]\n",
    "        team_out = row_out[\"team_short_name\"]\n",
    "        pos_out = row_out[\"position_label\"]\n",
    "        pool_pos = pool[pool[\"position_label\"] == pos_out]\n",
    "        for _, row_in in pool_pos.iterrows():\n",
    "            pid_in = row_in[\"player_id\"]\n",
    "            cost_in = row_in[\"now_cost_m\"]\n",
    "            score_in = row_in[score_col]\n",
    "            team_in = row_in[\"team_short_name\"]\n",
    "            new_cost = current_cost - cost_out + cost_in\n",
    "            if new_cost > budget_m:\n",
    "                continue\n",
    "            counts = team_counts.copy()\n",
    "            counts[team_out] = counts.get(team_out, 0) - 1\n",
    "            counts[team_in] = counts.get(team_in, 0) + 1\n",
    "            if any(v > max_from_team for v in counts.values()):\n",
    "                continue\n",
    "            gain = score_in - score_out\n",
    "            if gain <= 0:\n",
    "                continue\n",
    "            suggestions.append({\n",
    "                \"out_player_id\": pid_out,\n",
    "                \"out_name\": row_out[\"player_name\"],\n",
    "                \"out_team\": team_out,\n",
    "                \"out_pos\": pos_out,\n",
    "                \"out_cost\": cost_out,\n",
    "                \"out_score\": score_out,\n",
    "                \"in_player_id\": pid_in,\n",
    "                \"in_name\": row_in[\"player_name\"],\n",
    "                \"in_team\": team_in,\n",
    "                \"in_pos\": pos_out,\n",
    "                \"in_cost\": cost_in,\n",
    "                \"in_score\": score_in,\n",
    "                \"delta_cost\": cost_in - cost_out,\n",
    "                \"delta_score\": gain,\n",
    "            })\n",
    "    if not suggestions:\n",
    "        print(\"No positive-gain single-player swaps found under constraints.\")\n",
    "        return pd.DataFrame()\n",
    "    sugg_df = pd.DataFrame(suggestions).sort_values(\"delta_score\", ascending=False)\n",
    "    print(f\"Top {min(20, len(sugg_df))} single-transfer suggestions (selection_score gain):\")\n",
    "    display(sugg_df.head(20))\n",
    "    return sugg_df.head(50)\n",
    "\n",
    "# Example:\n",
    "# current_squad_ids = [...]\n",
    "# transfer_suggestions = suggest_transfers_greedy(snapshot_df, current_squad_ids, n_transfers=1, budget_m=100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O. Starting XI Selector for a Given Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_starting_xi_for_squad(\n",
    "    snapshot_df,\n",
    "    current_squad_ids,\n",
    "    max_from_team=3,\n",
    "    use_active_filter=True,\n",
    "    use_consistency_filter=True,\n",
    "    score_col=\"score_for_xi\",\n",
    "):\n",
    "    df = snapshot_df.copy()\n",
    "    df = df[df[\"player_id\"].isin(current_squad_ids)].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No overlapping players between snapshot_df and current_squad_ids.\")\n",
    "    if use_active_filter and \"roll_minutes_3wk\" in df.columns:\n",
    "        df = df[df[\"roll_minutes_3wk\"] > 0].copy()\n",
    "    if use_consistency_filter:\n",
    "        df = apply_consistency_filter(df)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No players left in squad after filters.\")\n",
    "    if score_col not in df.columns:\n",
    "        df[score_col] = build_selection_score(df)\n",
    "    prob = pulp.LpProblem(\"Starting_XI\", pulp.LpMaximize)\n",
    "    indices = list(df.index)\n",
    "    x = {i: pulp.LpVariable(f\"x_{i}\", cat=\"Binary\") for i in indices}\n",
    "    prob += pulp.lpSum(df.loc[i, score_col] * x[i] for i in indices)\n",
    "    prob += pulp.lpSum(x[i] for i in indices) == 11\n",
    "    pos_bounds = {\n",
    "        \"GK\": (1, 1),\n",
    "        \"DEF\": (3, 5),\n",
    "        \"MID\": (2, 5),\n",
    "        \"FWD\": (1, 3),\n",
    "    }\n",
    "    for pos, (min_c, max_c) in pos_bounds.items():\n",
    "        idx_pos = df.index[df[\"position_label\"] == pos].tolist()\n",
    "        if idx_pos:\n",
    "            prob += pulp.lpSum(x[i] for i in idx_pos) >= min_c\n",
    "            prob += pulp.lpSum(x[i] for i in idx_pos) <= max_c\n",
    "    for team, grp in df.groupby(\"team_short_name\"):\n",
    "        idx_team = grp.index.tolist()\n",
    "        prob += pulp.lpSum(x[i] for i in idx_team) <= max_from_team\n",
    "    _ = prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    selected_idx = [i for i in indices if pulp.value(x[i]) == 1]\n",
    "    xi = df.loc[selected_idx].copy()\n",
    "    xi = xi.sort_values([\"position_label\", score_col], ascending=[True, False])\n",
    "    xi[\"selection_score\"] = xi[score_col]\n",
    "    print(\"Starting XI (within your squad):\")\n",
    "    display(xi[[\n",
    "        \"player_id\", \"player_name\", \"team_short_name\", \"position_label\",\n",
    "        \"pred_rf_full\", \"selection_score\", \"tier\",\n",
    "        \"points_mean\", \"consistency_score\"\n",
    "    ]])\n",
    "    bench = df.loc[~df.index.isin(selected_idx)].copy()\n",
    "    bench = bench.sort_values(score_col, ascending=False)\n",
    "    print(\"Bench ordered by model score:\")\n",
    "    display(bench[[\n",
    "        \"player_id\", \"player_name\", \"team_short_name\", \"position_label\",\n",
    "        \"pred_rf_full\", score_col, \"tier\",\n",
    "        \"points_mean\", \"consistency_score\"\n",
    "    ]])\n",
    "    return xi, bench\n",
    "\n",
    "# Example:\n",
    "# current_squad_ids = [...]\n",
    "# starting_xi, bench = select_starting_xi_for_squad(snapshot_df, current_squad_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
